{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a9d8812-b656-4e84-a9b3-ee13db7f875c",
   "metadata": {},
   "source": [
    "# **OVERVIEW**\n",
    "\n",
    "\n",
    "The provided sources contain comprehensive information regarding the scientific and technical challenges and solutions surrounding autonomous navigation, simulation, and deep learning (DL) applications for spacecraft and robotic systems.\n",
    "\n",
    "### I. Challenges and Motivation for Deep Learning in Space Navigation\n",
    "\n",
    "**Data Scarcity and Environmental Challenges:**\n",
    "Acquiring labeled data from real space operational conditions is scarce due to the high costs and complexity of space missions, including restricted on-board resources for storage and transmission. This lack of data hinders the training of robust learning-based visual-based navigation (VBN) algorithms.\n",
    "\n",
    "Spaceborne pose estimation and navigation problems differ significantly from terrestrial tasks due to unique environmental factors, summarized as:\n",
    "*   Planets and stars acting as background distractors.\n",
    "*   Challenging visual conditions resulting from the lack of atmosphere and light diffusion.\n",
    "*   Much stronger shadows and varied illumination conditions, leading to extreme image contrast and low signal-to-noise ratio.\n",
    "*   Limited computational resources and power consumption constraints of space hardware.\n",
    "\n",
    "Deep Neural Networks (DNNs) are employed because they can adequately capture the intrinsic nonlinearities between input sensor data (such as images or Digital Elevation Maps (DEM)) and state estimates.\n",
    "\n",
    "### II. Synthetic Data Generation and Sim-to-Real Transfer\n",
    "\n",
    "**Simulation Tools for Synthetic Data:**\n",
    "To overcome data limitations, researchers rely on computer-based simulators to generate synthetic datasets.\n",
    "*   **SPIN (SPacecraft Imagery for Navigation)** is presented as the first open-source image generation tool specifically designed to create realistic data for visual-based navigation between two spacecraft. SPIN enables customization of key parameters including camera intrinsics, environmental illumination (Spotlight, Sunlight, Ambient Light), backgrounds (including Earth images), and material properties (high-quality reflective materials and specularity). SPIN generates extensive ground truth data, including **metric depth maps**, **segmentation masks**, **dense pose maps** (3D coordinates of each pixel), and keypoint heatmaps, which often lack in proprietary datasets. Validation showed that training a pose estimation model using SPIN-generated data resulted in a 53% average reduction in error rate when evaluating on testbed images (realistic imagery captured in laboratory conditions), demonstrating enhanced realism compared to existing synthetic datasets like SPEED+ and SHIRT.\n",
    "*   **SurRender** is Airbusâ€™s high-performance image simulator used for scenarios like Lunar landing and man-made objects (e.g., ENVISAT mock-up). It utilizes ray-tracing for physically rendered images, incorporating realistic reflections, secondary illumination, and self-occlusion. Datasets generated by SurRender were found adequate for training machine learning algorithms.\n",
    "*   **Model Capture** techniques have been developed to extract realistic textures and optical properties (like BRDFs and MLI models) from real laboratory mock-up images and inject them into SurRender simulations, enhancing visual fidelity.\n",
    "\n",
    "**Bridging the Sim-to-Real Gap:**\n",
    "The gap between models trained purely in simulation and their performance in the real world (the Sim-to-Real gap) is a key challenge. Two primary strategies address this:\n",
    "1.  **Domain Randomization (DR):** Involves deliberate randomization of visual properties (lighting, color, texture) in the source domain (simulation) so that the target domain (reality) appears as another variant, forcing the model to learn invariant features.\n",
    "2.  **Domain Adaptation (DA):** Aligns the source domain with the target domain using techniques like **Generative Adversarial Networks (GANs)**.\n",
    "    *   **CycleGAN** is an unpaired image-to-image translation model utilizing a cycle consistency loss, allowing domain translation (e.g., synthetic to real visual style) without requiring paired examples.\n",
    "    *   **Instance-Level Style Transfer:** A novel pipeline combines CycleGAN with the foundation model **Segment Anything Model (SAM)** to perform style transfer exclusively on specific regions (e.g., road asphalt) identified by SAM's segmentation mask. This approach ensures realism while preserving critical visual cues (like road markings), significantly improving robustness and generalizability in real-world scenarios compared to simulation-only or standard augmentation methods.\n",
    "\n",
    "### III. Deep Learning Methods for Space Applications\n",
    "\n",
    "**1. Spacecraft Relative Pose Estimation (Rendezvous):**\n",
    "The goal is to estimate the six Degree-of-Freedom (6-DoF) pose ($\\text{T}_{\\text{ct}}$) of a target spacecraft ($\\vec{F}_{\\text{t}}$) relative to a chaser ($\\vec{F}_{\\text{c}}$).\n",
    "*   **Direct DNN Methods (End-to-End):** The DNN estimates the pose directly from the input. Examples include the Spacecraft Pose Network (SPN), which combines a CNN backbone with R-CNN and uses soft classification for attitude estimation.\n",
    "*   **Indirect DNN Methods (Hybrid):** The DNN performs image processing tasks, such as detecting $2D$ keypoints or an image Region of Interest (RoI), and the final pose is determined by combining this output with classical methods like **Perspective-n-Point (PnP)** algorithms. PnP solves the pose using the $2D-3D$ correspondences between image keypoints and their $3D$ model counterparts. These hybrid solutions are often integrated with navigation filters, such as the **Extended Kalman Filter (EKF)**, to achieve continuous, smooth consistency in the pose estimate.\n",
    "*   **Recurrent Neural Networks (RNNs)**, particularly **Long Short-Term Memory (LSTM)**, are crucial for processing sequential data and modeling relative dynamics in continuous output missions like rendezvous and formation flying.\n",
    "\n",
    "**2. Terrain Relative Navigation (TRN):**\n",
    "This field uses DL for navigation during descent and landing on bodies like the Moon and asteroids.\n",
    "*   **Crater Detection and Identification:** Craters are ideal landmarks. CNNs based on U-Net architecture (like DeepMoon and LunaNet) are used to identify craters and output pixel-wise confidence maps of crater rims, often using DEM inputs. The PyCDA library is an open-source tool for crater detection.\n",
    "*   **Hazard Detection and Avoidance (HDA):** DNNs are used to classify safe and hazardous landing spots. Hourglass-like CNN architectures based on U-Net have been implemented to process DEMs and output confidence maps for safe landing zone detection.\n",
    "\n",
    "**3. Reinforcement Learning (RL) and Guidance, Navigation, and Control (GNC):**\n",
    "Deep RL methods are utilized to learn complex control and guidance policies for autonomous space operations.\n",
    "*   **Applications:** RL is applied to attitude control, orbital maneuvering, rendezvous, docking, hovering near asteroids, and fuel-optimal control during lunar landing.\n",
    "*   **Adaptability:** RL-based controllers (like those using the PPO or TD3 algorithms) can efficiently adapt in real-time to internal and external disturbances, such as actuator failures, rapid attitude changes, and unknown mass parameters or asteroid dynamics, without requiring retraining.\n",
    "*   **Meta-RL** is used to obtain adaptive guidance laws that can quickly adapt to changing environmental disturbances, such as landing on Mars with accidental engine failure or landing on asteroids with unknown models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6e21f5-ec5b-4cf3-812b-59ea0c59944c",
   "metadata": {},
   "source": [
    "# **Coordinate systems**\n",
    "\n",
    "Coordinate systems are fundamental to space operations, navigation, and mission planning. The space industry uses several different systems depending on the application:\n",
    "\n",
    "## Primary Coordinate Systems\n",
    "\n",
    "**Earth-Centered Inertial (ECI)** systems are fixed relative to distant stars and don't rotate with Earth. The most common is J2000, with its origin at Earth's center and axes pointing toward the vernal equinox and celestial north pole as they were on January 1, 2000. This system is ideal for orbital mechanics calculations and tracking satellites.\n",
    "\n",
    "**Earth-Centered Earth-Fixed (ECEF)** systems rotate with the planet. WGS84 is the standard, used by GPS and most terrestrial applications. The coordinates remain constant for fixed points on Earth's surface, making it perfect for ground station locations and launch sites.\n",
    "\n",
    "**Topocentric systems** are centered at a specific location on Earth, like a ground station or launch pad. These include East-North-Up (ENU) and North-East-Down (NED) frames, which are intuitive for local operations and tracking visible satellites.\n",
    "\n",
    "**Orbital reference frames** include the Radial-Transverse-Normal (RTN) system that moves with a spacecraft, making it useful for proximity operations and rendezvous maneuvers.\n",
    "\n",
    "## Specialized Systems\n",
    "\n",
    "For lunar and planetary missions, selenographic and planetocentric coordinates are used, centered on the Moon or respective planet. Deep space missions often use heliocentric systems centered on the Sun.\n",
    "\n",
    "The International Celestial Reference Frame (ICRF) serves as the fundamental standard for precise astronomical positioning, based on distant quasars that provide extremely stable reference points.\n",
    "\n",
    "## Why Multiple Systems?\n",
    "\n",
    "Different coordinate systems simplify different calculations. ECI makes orbital propagation straightforward, ECEF simplifies ground tracking, and orbital frames make relative navigation easier. Converting between systems requires careful handling of rotation rates, precession, and relativistic effects for high-precision work.\n",
    "\n",
    "Is there a particular coordinate system or application you'd like to explore in more detail?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9ffe8-2c57-4d55-b174-4869445b6bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "OK "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
